setwd("~/Desktop/Federal-Paper-Authorship-Classification")
setwd("~/Desktop/Federal-Paper-Authorship-Classification")
library(tm)
library(SnowballC)
# This code uses tm to p
# Make dictionary sorted by number of times a word appears in corpus
# (useful for using commonly appearing words as factors)
# NOTE: Use the *entire* corpus: training, testing, spam and ham
make.sorted.dictionary.df <- function(infiles){
# This returns a dataframe that is sorted by the number of times
# a word appears
# List of vectors to one big vetor
dictionary.full <- unlist(infiles)
# Tabulates the full dictionary
tabulate.dic <- tabulate(factor(dictionary.full))
# Find unique values
dictionary <- unique(dictionary.full)
# Sort them alphabetically
dictionary <- sort(dictionary)
dictionary.df <- data.frame(word = dictionary, count = tabulate.dic)
sort.dictionary.df <- dictionary.df[order(dictionary.df$count,decreasing=TRUE),];
return(sort.dictionary.df)
}
##########################################
dictionary <- make.sorted.dictionary.df(c(hamilton.train,hamilton.test,madison.train,madison.test))
##########################################
# Make a document-term matrix, which counts the number of times each
# dictionary element is used in a document
make.document.term.matrix <- function(infiles,dictionary){
# This takes the text and dictionary objects from above and outputs a
# document term matrix
num.infiles <- length(infiles);
num.words <- nrow(dictionary);
# Instantiate a matrix where rows are documents and columns are words
dtm <- mat.or.vec(num.infiles,num.words); # A matrix filled with zeros
for (i in 1:num.infiles){
num.words.infile <- length(infiles[[i]]);
infile.temp <- infiles[[i]];
for (j in 1:num.words.infile){
ind <- which(dictionary == infile.temp[j])[[1]];
# print(sprintf('%s,%s', i , ind))
dtm[i,ind] <- dtm[i,ind] + 1;
}
}
return(dtm);
}
##########################################
dtm.hamilton.test<-make.document.term.matrix(hamilton.test,dictionary)
dtm.madison.test <- make.document.term.matrix(madison.test,dictionary)
dtm.hamilton.train<-make.document.term.matrix(hamilton.train,dictionary)
dtm.madison.train<-make.document.term.matrix(madison.train,dictionary)
preprocess.directory = function(dirname){
# the directory must have all the relevant text files
ds = DirSource(dirname)
# Corpus will make a tm document corpus from this directory
fp = Corpus( ds )
# inspect to verify
# inspect(fp[1])
# another useful command
# identical(fp[[1]], fp[["Federalist01.txt"]])
# now let us iterate through and clean this up using tm functionality
# make all words lower case
fp = tm_map( fp , content_transformer(tolower));
# remove all punctuation
fp = tm_map( fp, removePunctuation);
# remove stopwords like the, a, and so on.
fp = tm_map( fp, removeWords, stopwords("english"));
# remove stems like suffixes
fp = tm_map( fp, stemDocument)
# remove extra whitespace
fp = tm_map( fp, stripWhitespace)
# now write the corpus out to the files for our future use.
# MAKE SURE THE _CLEAN DIRECTORY EXISTS
writeCorpus( fp , sprintf('%s_clean',dirname), filenames = names(fp))
}
##########################################
preprocess.directory("fp_hamilton_test")
preprocess.directory('fp_hamilton_train')
preprocess.directory('fp_madison_test')
preprocess.directory('fp_madison_train')
##########################################
# To read in data from the directories:
# Partially based on code from C. Shalizi
read.directory <- function(dirname) {
# Store the infiles in a list
infiles = list();
# Get a list of filenames in the directory
filenames = dir(dirname,full.names=TRUE);
for (i in 1:length(filenames)){
infiles[[i]] = scan(filenames[i],what="",quiet=TRUE);
}
return(infiles)
}
##########################################
hamilton.test<-read.directory("fp_hamilton_test_clean")
hamilton.train<-read.directory("fp_hamilton_train_clean")
madison.test<-read.directory("fp_madison_test_clean")
madison.train<-read.directory("fp_madison_train_clean")
##########################################
# Make dictionary sorted by number of times a word appears in corpus
# (useful for using commonly appearing words as factors)
# NOTE: Use the *entire* corpus: training, testing, spam and ham
make.sorted.dictionary.df <- function(infiles){
# This returns a dataframe that is sorted by the number of times
# a word appears
# List of vectors to one big vetor
dictionary.full <- unlist(infiles)
# Tabulates the full dictionary
tabulate.dic <- tabulate(factor(dictionary.full))
# Find unique values
dictionary <- unique(dictionary.full)
# Sort them alphabetically
dictionary <- sort(dictionary)
dictionary.df <- data.frame(word = dictionary, count = tabulate.dic)
sort.dictionary.df <- dictionary.df[order(dictionary.df$count,decreasing=TRUE),];
return(sort.dictionary.df)
}
##########################################
dictionary <- make.sorted.dictionary.df(c(hamilton.train,hamilton.test,madison.train,madison.test))
##########################################
# Make a document-term matrix, which counts the number of times each
# dictionary element is used in a document
make.document.term.matrix <- function(infiles,dictionary){
# This takes the text and dictionary objects from above and outputs a
# document term matrix
num.infiles <- length(infiles);
num.words <- nrow(dictionary);
# Instantiate a matrix where rows are documents and columns are words
dtm <- mat.or.vec(num.infiles,num.words); # A matrix filled with zeros
for (i in 1:num.infiles){
num.words.infile <- length(infiles[[i]]);
infile.temp <- infiles[[i]];
for (j in 1:num.words.infile){
ind <- which(dictionary == infile.temp[j])[[1]];
# print(sprintf('%s,%s', i , ind))
dtm[i,ind] <- dtm[i,ind] + 1;
}
}
return(dtm);
}
##########################################
dtm.hamilton.test<-make.document.term.matrix(hamilton.test,dictionary)
dtm.madison.test <- make.document.term.matrix(madison.test,dictionary)
dtm.hamilton.train<-make.document.term.matrix(hamilton.train,dictionary)
dtm.madison.train<-make.document.term.matrix(madison.train,dictionary)
View(dtm.hamilton.train)
View(dtm.hamilton.train)
dtm.train<-rbind(dtm.hamilton.train,dtm.madison.train)
P.hamilton<-colSums(dtm.hamilton.train)/sum(dtm.hamilton.train)
P.hamilton
P.madison<-colSums(dtm.madison.train)/sum(dtm.madison.train)
P<-colSums(dtm.train)/sum(dtm.train)
p.hamilton<-nrow(dtm.hamilton.train)/nrow(dtm.train)
p.madison<-nrow(dtm.madison.train)/nrow(dtm.train)
mutual.information<-P.hamilton*p.hamilton*log(P.hamilton/P)+(1-P.hamilton)*p.hamilton*log((1-P.hamilton)/(1-P))+P.madison*p.madison*log(P.madison/P)+(1-P.madison)*p.madison*log((1-P.madison)/(1-P))
mutual.information[is.na(mutual.information)]<-0
dictionary.muinfo<-data.frame(sorted.dictionary$word,mutual.information,row.names=c(1:4875))
dim(mutual.information)
dictionary.muinfo<-data.frame(as.vector(dictionary$word),mutual.information,row.names=c(1:4875))
View(dictionary.muinfo)
View(dictionary.muinfo)
names(dictionary.muinfo)<-c("word.muinfo","value")
sorted.muinfo<-dictionary.muinfo[order(dictionary.muinfo$word.muinfo,decreasing=T),]
View(sorted.muinfo)
View(sorted.muinfo)
View(sorted.muinfo)
View(sorted.muinfo)
sorted.muinfo<-dictionary.muinfo[order(dictionary.muinfo$value,decreasing=T),]
install.packages("e1071")
library(e1071)
index.train <- as.factor(rep(0:1,c(nrow(dtm.madison.train),nrow(dtm.hamilton.train))))
dtm.train <- cbind(index.train,rbind(dtm.madison.train,dtm.hamilton.train))
index.test <- as.factor(rep(0:1,c(nrow(dtm.madison.test),nrow(dtm.hamilton.test))))
dtm.test<-cbind(index.test,rbind(dtm.madison.test,dtm.hamilton.test))
dtm.train[,2:ncol(dtm.train)] <- scale(dtm.train[,2:ncol(dtm.train)] , center = TRUE, scale = TRUE)
dtm.test[,2:ncol(dtm.test)] <- scale(dtm.train[,2:ncol(dtm.test)],center = T, scale = T)
dim(dtm.test)
index.train <- as.factor(rep(0:1,c(nrow(dtm.madison.train),nrow(dtm.hamilton.train))))
dtm.train <- cbind(index.train,rbind(dtm.madison.train,dtm.hamilton.train))
index.test <- as.factor(rep(0:1,c(nrow(dtm.madison.test),nrow(dtm.hamilton.test))))
dtm.test<-cbind(index.test,rbind(dtm.madison.test,dtm.hamilton.test))
dtm.train[,2:ncol(dtm.train)] <- scale(dtm.train[,2:ncol(dtm.train)] , center = TRUE, scale = TRUE)
dtm.test[,2:ncol(dtm.test)] <- scale(dtm.train[,2:ncol(dtm.test)],center = T, scale = T)
dim(dtm.train[,2:ncol(dtm.test)])
dim(dtm.test[,2:ncol(dtm.test)])
library(glmnet)
library(caret)
dtm.train[,2:ncol(dtm.train)] <- scale(dtm.train[,2:ncol(dtm.train)] , center = TRUE, scale = TRUE)
dtm.test[,2:ncol(dtm.test)] <- scale(dtm.test[,2:ncol(dtm.test)],center = T, scale = T)
dtm.train[is.nan(dtm.train)]=0
dtm.test[is.nan(dtm.test)]=0
#using ridge regression model on the training data
colnames(dtm.train)<-c("index.train",as.vector(dictionary$word))
fit.ridge <- cv.glmnet(dtm.train[,2:ncol(dtm.train)],dtm.train[,1], family="binomial", alpha = 0, standardize=F)
plot(fit.ridge)
pred.ridge<-predict(fit.ridge,dtm.test[,2:ncol(dtm.test)],s="lambda.min",type="class")
confusionMatrix(as.numeric(pred.ridge),dtm.test[,1])
coef.ridge<-coef(fit.ridge, s="lambda.min")
coef.ridge[order(abs(coef.ridge[,1]),decreasing = T),][1:11]
dtm.test[,2:ncol(dtm.test)] <- scale(dtm.test[,2:ncol(dtm.test)],center = T, scale = T)
dtm.train[is.nan(dtm.train)]=0
dtm.test[is.nan(dtm.test)]=0
?svm
svm.model<-svm(dtm.train[,1:101][,-1],dtm.train[,1:101][,1],type='C',kernel='linear')
model.pred<-predict(svm.model,dtm.test[,1:101][,-1])
model.pred
dtm.train[,1:101][,1]
View(dtm.test)
View(dtm.test)
View(dtm.train)
View(dtm.train)
confusionMatrix(as.numeric(model.pred),dtm.test[,1])
svm.model<-svm(dtm.train[,2:101],dtm.train[,1],type='C',kernel='linear')
model.pred<-predict(svm.model,dtm.test[,1:101][,-1])
confusionMatrix(as.numeric(model.pred),dtm.test[,1])
model.pred<-predict(svm.model,dtm.test[,2:101])
confusionMatrix(as.numeric(model.pred),dtm.test[,1])
svm.model<-svm(dtm.train[,2:101],dtm.train[,1],kernel='linear',cost=0.01)
model.pred<-predict(svm.model,dtm.test[,2:101])
confusionMatrix(as.numeric(model.pred),dtm.test[,1])
model.pred
svm.model<-svm(dtm.train[,2:101],dtm.train[,1],type="C",kernel='linear')
model.pred<-predict(svm.model,dtm.test[,2:101])
confusionMatrix(as.numeric(model.pred),dtm.test[,1])
index.train <- as.factor(rep(0:1,c(nrow(dtm.madison.train),nrow(dtm.hamilton.train))))
dtm.train <- cbind(index.train,rbind(dtm.madison.train,dtm.hamilton.train))
index.test <- as.factor(rep(0:1,c(nrow(dtm.madison.test),nrow(dtm.hamilton.test))))
dtm.test<-cbind(index.test,rbind(dtm.madison.test,dtm.hamilton.test))
dtm.train[,2:ncol(dtm.train)] <- scale(dtm.train[,2:ncol(dtm.train)] , center = TRUE, scale = TRUE)
dtm.test[,2:ncol(dtm.test)] <- scale(dtm.test[,2:ncol(dtm.test)],center = T, scale = T)
svm.model<-svm(dtm.train[,2:101],dtm.train[,1],type="C",kernel='linear')
model.pred<-predict(svm.model,dtm.test[,2:101])
confusionMatrix(as.numeric(model.pred),dtm.test[,1])
model<-svm(dtm.train[,2:101],dtm.train[,1],type="C",kernel="radial")
model.pred<-predict(svm.model,dtm.test[,2:101])
confusionMatrix(as.numeric(model.pred),dtm.test[,1])
