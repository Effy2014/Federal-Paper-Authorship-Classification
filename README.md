# Federal Paper Authorship Classification

* Cleaning the dataset, storing the data in the form of tokens, building a dictionary containing document number, word number and count for that word-document combination.

* Building a Naive Bayes classifier; using cross validation finding the best tunable parameter mu for Naive Bayes.

* Using decision tree with Gini impurity cofficient splits and information gain splits.  

* Centered and scaled document term matrices were used for regularized logistic regression. The data is regularized because p>n for this data.

